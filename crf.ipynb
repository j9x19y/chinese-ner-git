{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn_crfsuite import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 读取语料\n",
    "# def read_corpus(sents_path, tags_path):\n",
    "#     corpus = []\n",
    "#     with open(sents_path, 'r', encoding='utf-8') as f1, open(tags_path, 'r', encoding='utf-8') as f2:\n",
    "#         for line_sent, line_tag in zip(f1.readlines(), f2.readlines()):\n",
    "#             line_sent = line_sent.strip().split()\n",
    "#             line_tag = line_tag.strip().split()\n",
    "#             assert len(line_sent) == len(line_tag)\n",
    "#             corpus.append((line_sent, line_tag))\n",
    "#     return corpus\n",
    "\n",
    "\n",
    "# # 读取标签信息\n",
    "# def read_tags(file_path):\n",
    "#     tags = []\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         for line in f.readlines():\n",
    "#             line = line.strip()\n",
    "#             tags.append(line)\n",
    "#     return tags\n",
    "\n",
    "# train_sent_path = 'dataset/MSRA/train/sentences.txt'\n",
    "# train_tag_path = 'dataset/MSRA/train/tags.txt'\n",
    "\n",
    "# test_sent_path = 'dataset/MSRA/test/sentences.txt'\n",
    "# test_tag_path = 'dataset/MSRA/test/tags.txt'\n",
    "\n",
    "# train_corpos = read_corpus(train_sent_path, train_tag_path)\n",
    "# test_corpos = read_corpus(test_sent_path, test_tag_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset/train.csv', 'w', encoding='utf-8') as f:\n",
    "#     f.write('Sentence_Index,Token,Tag\\n')\n",
    "#     id = 0\n",
    "#     for c in train_corpos:\n",
    "#         for i in range(len(c[0])):\n",
    "#             f.write(str(id)+','+c[0][i]+','+c[1][i]+'\\n')\n",
    "#         id += 1\n",
    "\n",
    "# with open('dataset/test.csv', 'w', encoding='utf-8') as f:\n",
    "#     f.write('Sentence_Index,Token,Tag\\n')\n",
    "#     id = 0\n",
    "#     for c in test_corpos:\n",
    "#         for i in range(len(c[0])):\n",
    "#             f.write(str(id)+','+c[0][i]+','+c[1][i]+'\\n')\n",
    "#         id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "train_df['Token'].fillna('NA', inplace=True)\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "test_df['Token'].fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>如</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>何</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>解</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>决</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>足</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_Index Token Tag\n",
       "0               0     如   O\n",
       "1               0     何   O\n",
       "2               0     解   O\n",
       "3               0     决   O\n",
       "4               0     足   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>中</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>共</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>中</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>央</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>致</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_Index Token    Tag\n",
       "0               0     中  B-ORG\n",
       "1               0     共  I-ORG\n",
       "2               0     中  I-ORG\n",
       "3               0     央  I-ORG\n",
       "4               0     致      O"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence_features(df):\n",
    "    '''\n",
    "    每个标记的特征是基于其自身以及上一个和下一个标记的上下文信息。\n",
    "    '''\n",
    "    sentence_length = len(df)\n",
    "\n",
    "    for i in range(sentence_length):\n",
    "        token = df.iloc[i]['Token']\n",
    "\n",
    "        features = {\n",
    "            'bias': 1.0,    # 偏置项，用于模型的训练。\n",
    "            'w':token,\n",
    "            # 'token.isdigit()': token.isdigit()\n",
    "        }\n",
    "\n",
    "        # if i > 0:：如果不是句子的第一个标记，执行以下代码块：\n",
    "        # 获取前一个标记的文本内容，并添加以下特征：\n",
    "        if i > 0:\n",
    "            previous_token = df.iloc[i-1]['Token']\n",
    "            features.update({\n",
    "                'w-1':previous_token,\n",
    "                'w-1:w':previous_token+token,\n",
    "                # 'previous_token.isdigit()': previous_token.isdigit()\n",
    "            })\n",
    "        # 如果是句子的第一个标记，添加特殊特征 'BOS'（Beginning of Sentence）。\n",
    "        else:\n",
    "            features['BOS'] = True\n",
    "\n",
    "        # 如果不是句子的最后一个标记，执行以下代码块：\n",
    "        # 获取后一个标记的文本内容，并添加以下特征：\n",
    "        if i < sentence_length - 1:\n",
    "            posterior_token = df.iloc[i+1]['Token']\n",
    "            features.update({\n",
    "                'w+1':posterior_token,\n",
    "                'w+1:w':posterior_token+token,\n",
    "                # 'posterior_token.isdigit()': posterior_token.isdigit()\n",
    "            })\n",
    "        # 如果是句子的最后一个标记，添加特殊特征 'EOS'（End of Sentence）。\n",
    "        else:\n",
    "            features['EOS'] = True\n",
    "\n",
    "        yield features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df, include_y=False):\n",
    "    X, y = [], []\n",
    "    for _, group_df in df.groupby(['Sentence_Index']):\n",
    "        X.append(list(extract_sentence_features(group_df)))\n",
    "        if include_y:\n",
    "            y.append(group_df['Tag'])\n",
    "    if include_y:\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare(train_df, include_y=True)\n",
    "X_test, y_test = prepare(test_df, include_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3442"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(X_train)\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    delta=0.001,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 42000/42000 [00:09<00:00, 4333.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 665358\n",
      "Seconds required: 2.715\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.300000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.001000\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=1.47  loss=1819823.93 active=657735 feature_norm=1.00\n",
      "Iter 2   time=0.82  loss=1541376.29 active=650082 feature_norm=4.21\n",
      "Iter 3   time=0.76  loss=1328406.03 active=651920 feature_norm=3.67\n",
      "Iter 4   time=3.98  loss=1057278.84 active=310152 feature_norm=1.99\n",
      "Iter 5   time=0.74  loss=1046701.57 active=665298 feature_norm=3.30\n",
      "Iter 6   time=0.71  loss=878787.11 active=665281 feature_norm=3.18\n",
      "Iter 7   time=2.81  loss=703666.26 active=582539 feature_norm=3.34\n",
      "Iter 8   time=1.39  loss=699062.84 active=551127 feature_norm=3.90\n",
      "Iter 9   time=0.73  loss=645768.00 active=621027 feature_norm=3.99\n",
      "Iter 10  time=0.74  loss=624294.08 active=620308 feature_norm=4.31\n",
      "Iter 11  time=0.71  loss=586216.96 active=619558 feature_norm=5.34\n",
      "Iter 12  time=0.73  loss=568447.98 active=398466 feature_norm=6.07\n",
      "Iter 13  time=0.71  loss=533547.47 active=365339 feature_norm=6.62\n",
      "Iter 14  time=2.08  loss=517678.00 active=360161 feature_norm=7.28\n",
      "Iter 15  time=0.74  loss=488978.90 active=360181 feature_norm=8.00\n",
      "Iter 16  time=1.39  loss=476691.85 active=334675 feature_norm=8.78\n",
      "Iter 17  time=0.78  loss=458335.49 active=334418 feature_norm=9.58\n",
      "Iter 18  time=0.75  loss=426833.29 active=328728 feature_norm=11.07\n",
      "Iter 19  time=0.74  loss=399300.85 active=324315 feature_norm=13.39\n",
      "Iter 20  time=1.47  loss=385960.63 active=320897 feature_norm=15.77\n",
      "Iter 21  time=0.72  loss=368219.12 active=334573 feature_norm=16.68\n",
      "Iter 22  time=0.74  loss=346598.56 active=328949 feature_norm=19.06\n",
      "Iter 23  time=0.71  loss=300570.06 active=318758 feature_norm=25.81\n",
      "Iter 24  time=0.72  loss=266261.48 active=299283 feature_norm=28.80\n",
      "Iter 25  time=0.75  loss=232536.43 active=292438 feature_norm=35.35\n",
      "Iter 26  time=0.70  loss=209765.48 active=292571 feature_norm=37.38\n",
      "Iter 27  time=0.70  loss=198058.75 active=291814 feature_norm=39.93\n",
      "Iter 28  time=0.69  loss=181305.15 active=290182 feature_norm=44.01\n",
      "Iter 29  time=0.70  loss=164846.44 active=285150 feature_norm=50.24\n",
      "Iter 30  time=0.77  loss=151924.28 active=284867 feature_norm=54.67\n",
      "Iter 31  time=0.76  loss=137845.31 active=276403 feature_norm=61.49\n",
      "Iter 32  time=0.78  loss=124757.15 active=260501 feature_norm=68.79\n",
      "Iter 33  time=0.76  loss=117899.14 active=256882 feature_norm=75.00\n",
      "Iter 34  time=0.76  loss=110250.47 active=260750 feature_norm=77.93\n",
      "Iter 35  time=0.72  loss=104620.68 active=258225 feature_norm=81.55\n",
      "Iter 36  time=0.75  loss=94043.69 active=234932 feature_norm=90.52\n",
      "Iter 37  time=1.49  loss=91390.38 active=231996 feature_norm=95.13\n",
      "Iter 38  time=0.75  loss=84403.57 active=219735 feature_norm=102.34\n",
      "Iter 39  time=0.77  loss=79021.96 active=217581 feature_norm=108.96\n",
      "Iter 40  time=0.73  loss=71348.53 active=209732 feature_norm=123.45\n",
      "Iter 41  time=0.73  loss=67830.56 active=203284 feature_norm=129.84\n",
      "Iter 42  time=0.74  loss=64753.38 active=200496 feature_norm=135.62\n",
      "Iter 43  time=0.75  loss=59537.06 active=194324 feature_norm=147.70\n",
      "Iter 44  time=1.46  loss=58455.23 active=191158 feature_norm=153.82\n",
      "Iter 45  time=0.72  loss=54875.90 active=187057 feature_norm=160.47\n",
      "Iter 46  time=0.72  loss=52778.35 active=179254 feature_norm=166.08\n",
      "Iter 47  time=0.70  loss=49407.66 active=172608 feature_norm=176.51\n",
      "Iter 48  time=0.69  loss=47506.10 active=166132 feature_norm=183.29\n",
      "Iter 49  time=0.74  loss=45703.27 active=164239 feature_norm=187.98\n",
      "Iter 50  time=0.73  loss=44079.03 active=159969 feature_norm=193.11\n",
      "Iter 51  time=0.70  loss=43319.24 active=147169 feature_norm=206.23\n",
      "Iter 52  time=0.70  loss=41641.54 active=146809 feature_norm=208.73\n",
      "Iter 53  time=0.69  loss=41321.93 active=144975 feature_norm=209.98\n",
      "Iter 54  time=0.70  loss=39600.80 active=139288 feature_norm=219.77\n",
      "Iter 55  time=2.08  loss=39217.10 active=138411 feature_norm=221.96\n",
      "Iter 56  time=0.69  loss=38657.21 active=135947 feature_norm=222.75\n",
      "Iter 57  time=0.69  loss=38006.41 active=131814 feature_norm=223.53\n",
      "Iter 58  time=0.72  loss=37382.04 active=129565 feature_norm=224.69\n",
      "Iter 59  time=0.71  loss=36867.09 active=125557 feature_norm=226.58\n",
      "Iter 60  time=0.69  loss=36372.91 active=122187 feature_norm=230.10\n",
      "Iter 61  time=0.70  loss=36017.38 active=119142 feature_norm=231.53\n",
      "Iter 62  time=0.71  loss=35632.82 active=115100 feature_norm=233.64\n",
      "Iter 63  time=0.69  loss=35261.11 active=109767 feature_norm=234.08\n",
      "Iter 64  time=0.72  loss=34909.34 active=107313 feature_norm=234.91\n",
      "Iter 65  time=0.70  loss=34647.83 active=105636 feature_norm=234.80\n",
      "Iter 66  time=0.68  loss=34393.89 active=102582 feature_norm=235.73\n",
      "Iter 67  time=0.71  loss=34167.44 active=101266 feature_norm=236.11\n",
      "Iter 68  time=0.70  loss=33956.27 active=99469 feature_norm=236.85\n",
      "Iter 69  time=0.71  loss=33786.94 active=98189 feature_norm=236.95\n",
      "Iter 70  time=0.70  loss=33622.22 active=97223 feature_norm=237.44\n",
      "Iter 71  time=0.70  loss=33461.60 active=96122 feature_norm=237.44\n",
      "Iter 72  time=0.68  loss=33312.82 active=95034 feature_norm=237.79\n",
      "Iter 73  time=0.68  loss=33184.20 active=94253 feature_norm=237.81\n",
      "Iter 74  time=0.71  loss=33067.14 active=93177 feature_norm=238.06\n",
      "Iter 75  time=0.72  loss=32959.65 active=91989 feature_norm=238.08\n",
      "Iter 76  time=0.69  loss=32861.37 active=91181 feature_norm=238.22\n",
      "Iter 77  time=0.69  loss=32767.71 active=90021 feature_norm=238.22\n",
      "Iter 78  time=0.71  loss=32686.82 active=88941 feature_norm=238.29\n",
      "Iter 79  time=0.69  loss=32610.21 active=88074 feature_norm=238.21\n",
      "Iter 80  time=0.70  loss=32539.45 active=87200 feature_norm=238.28\n",
      "Iter 81  time=0.70  loss=32475.28 active=86360 feature_norm=238.22\n",
      "Iter 82  time=0.69  loss=32414.86 active=85634 feature_norm=238.29\n",
      "Iter 83  time=0.71  loss=32355.12 active=84960 feature_norm=238.21\n",
      "Iter 84  time=0.70  loss=32292.46 active=84266 feature_norm=238.20\n",
      "Iter 85  time=0.74  loss=32237.59 active=83481 feature_norm=238.09\n",
      "Iter 86  time=0.79  loss=32188.75 active=83030 feature_norm=238.11\n",
      "Iter 87  time=0.75  loss=32143.10 active=82465 feature_norm=237.99\n",
      "Iter 88  time=0.71  loss=32096.02 active=81942 feature_norm=237.97\n",
      "Iter 89  time=0.70  loss=32053.07 active=81475 feature_norm=237.78\n",
      "Iter 90  time=0.76  loss=32013.04 active=81032 feature_norm=237.76\n",
      "Iter 91  time=0.73  loss=31976.78 active=80692 feature_norm=237.62\n",
      "Iter 92  time=0.90  loss=31941.85 active=80376 feature_norm=237.59\n",
      "Iter 93  time=0.85  loss=31902.12 active=79902 feature_norm=237.46\n",
      "Iter 94  time=0.84  loss=31867.32 active=79347 feature_norm=237.40\n",
      "Iter 95  time=0.77  loss=31834.40 active=78980 feature_norm=237.28\n",
      "Iter 96  time=0.70  loss=31805.70 active=78816 feature_norm=237.30\n",
      "Iter 97  time=0.70  loss=31777.14 active=78569 feature_norm=237.21\n",
      "Iter 98  time=0.70  loss=31744.35 active=78152 feature_norm=237.18\n",
      "Iter 99  time=0.68  loss=31716.22 active=77727 feature_norm=237.09\n",
      "Iter 100 time=0.70  loss=31688.97 active=77628 feature_norm=237.15\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 84.892\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 77628 (665358)\n",
      "Number of active attributes: 51122 (600868)\n",
      "Number of active labels: 7 (7)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# crf.fit(X_train, y_train)\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-ORG  -> I-ORG   6.266624\n",
      "B-PER  -> I-PER   3.919506\n",
      "I-PER  -> I-PER   3.626846\n",
      "O      -> O       3.560464\n",
      "B-ORG  -> I-ORG   3.428959\n",
      "I-LOC  -> I-LOC   2.929716\n",
      "B-LOC  -> I-LOC   2.910829\n",
      "O      -> B-ORG   1.491918\n",
      "O      -> B-PER   0.588304\n",
      "O      -> B-LOC   0.410751\n",
      "I-LOC  -> O       -0.077332\n",
      "I-LOC  -> B-LOC   -0.078167\n",
      "I-PER  -> O       -0.092089\n",
      "I-ORG  -> O       -0.248649\n",
      "I-PER  -> B-PER   -0.745519\n",
      "B-LOC  -> B-LOC   -0.927507\n",
      "I-LOC  -> B-ORG   -1.144386\n",
      "I-PER  -> B-ORG   -1.279218\n",
      "I-ORG  -> B-ORG   -1.338060\n",
      "B-LOC  -> O       -1.516935\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-ORG  -> B-PER   -4.680955\n",
      "B-ORG  -> O       -4.746733\n",
      "B-PER  -> B-LOC   -4.811949\n",
      "B-PER  -> I-ORG   -4.820961\n",
      "I-ORG  -> I-PER   -4.978876\n",
      "I-PER  -> I-ORG   -5.169316\n",
      "B-LOC  -> B-PER   -5.291380\n",
      "B-ORG  -> I-PER   -5.564023\n",
      "B-LOC  -> I-PER   -5.709079\n",
      "B-ORG  -> B-LOC   -5.917233\n",
      "I-LOC  -> I-PER   -5.987680\n",
      "I-PER  -> I-LOC   -6.282041\n",
      "I-ORG  -> I-LOC   -6.506312\n",
      "B-PER  -> I-LOC   -6.591651\n",
      "B-ORG  -> I-LOC   -6.915939\n",
      "B-LOC  -> I-ORG   -7.055764\n",
      "O      -> I-PER   -7.067027\n",
      "I-LOC  -> I-ORG   -7.298949\n",
      "O      -> I-ORG   -7.894202\n",
      "O      -> I-LOC   -8.422682\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "9.761739 O        w:、\n",
      "8.312941 O        w:，\n",
      "8.256189 B-PER    w-1:w:马列\n",
      "8.246758 B-PER    w:袁\n",
      "7.820297 B-PER    w:刘\n",
      "7.388132 B-PER    w:赵\n",
      "7.378631 I-LOC    w-1:w:埃及\n",
      "7.344671 B-PER    w:薛\n",
      "7.089330 B-ORG    w+1:w:指道\n",
      "7.073043 B-ORG    w+1:w:大联\n",
      "7.023772 B-ORG    w+1:w:合共\n",
      "7.003327 O        w:某\n",
      "6.948690 B-LOC    w:淮\n",
      "6.863508 O        w:的\n",
      "6.774855 B-PER    w-1:w:老于\n",
      "6.705571 O        w:等\n",
      "6.490065 B-PER    w:邓\n",
      "6.397761 O        w:在\n",
      "6.244106 B-PER    w:郭\n",
      "6.239973 O        w:与\n",
      "6.113476 I-ORG    w-1:w:一汽\n",
      "6.034832 O        w:是\n",
      "5.995766 B-PER    w:靳\n",
      "5.972042 B-LOC    w+1:w:药中\n",
      "5.928725 B-ORG    w-1:w:入盟\n",
      "5.926247 O        EOS\n",
      "5.890072 B-PER    w:李\n",
      "5.780547 O        w:对\n",
      "5.756613 O        w+1:w:区市\n",
      "5.724364 B-LOC    w+1:w:方中\n",
      "\n",
      "Top negative:\n",
      "-4.403203 O        w+1:w:会国\n",
      "-4.411551 O        w+1:w:外中\n",
      "-4.434201 O        w:厄\n",
      "-4.438736 O        w:瑞\n",
      "-4.484127 O        w:德\n",
      "-4.491924 O        w:沪\n",
      "-4.533850 O        w:萨\n",
      "-4.575599 O        w:曼\n",
      "-4.611519 O        w:曹\n",
      "-4.723146 I-ORG    w-1:队\n",
      "-4.744141 O        w:江\n",
      "-4.765595 I-LOC    w-1:省\n",
      "-4.800465 O        w:伊\n",
      "-4.801662 I-LOC    w-1:县\n",
      "-4.994937 O        w:尼\n",
      "-5.089502 O        w:川\n",
      "-5.097604 O        w:罗\n",
      "-5.168670 O        w:巴\n",
      "-5.218912 O        w:斯\n",
      "-5.242726 O        w:黎\n",
      "-5.300611 O        w:鲁\n",
      "-5.316671 O        w:菲\n",
      "-5.686188 O        w:华\n",
      "-5.798301 O        w:俄\n",
      "-5.868152 O        w-1:w:日本\n",
      "-5.889560 O        w:韩\n",
      "-6.401225 O        w:欧\n",
      "-6.636296 O        w:亚\n",
      "-6.828994 O        w:澳\n",
      "-8.478345 O        w:京\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.93      0.85      0.89      2886\n",
      "         ORG       0.80      0.77      0.79      1331\n",
      "         PER       0.85      0.67      0.75      1973\n",
      "\n",
      "   micro avg       0.88      0.77      0.82      6190\n",
      "   macro avg       0.86      0.76      0.81      6190\n",
      "weighted avg       0.88      0.77      0.82      6190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "list_y_test = [s.tolist() for s in y_test]\n",
    "\n",
    "report = classification_report(list_y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(crf)\n",
    "with open('crf.model','wb+') as f:\n",
    "\tf.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('crf.model','rb') #注意此处model是rb\n",
    "s = f.read()\n",
    "model = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本报洛杉矶１１月２日电记者陈特安、何洪泽报道：今天中午，洛杉矶市民议政论坛、亚洲协会南加中心、美中关系全国委员会、美中友协美西分会等四个友好团体在比佛利山的希尔顿饭店举行盛大午宴，热烈欢迎正在洛杉矶访问的中国国家主席江泽民及其一行。\n",
      "test data: \n",
      "\tLOC: 洛杉矶\n",
      "\tPER: 陈特安\n",
      "\tPER: 何洪泽\n",
      "\tORG: 洛杉矶市民议政论坛\n",
      "\tORG: 亚洲协会南加中心\n",
      "\tORG: 美中关系全国委员会\n",
      "\tORG: 美中友协美西分会\n",
      "\tLOC: 比佛利山\n",
      "\tORG: 希尔顿饭店\n",
      "\tLOC: 洛杉矶\n",
      "\tLOC: 中国\n",
      "\tPER: 江泽民\n",
      "\n",
      "pred result: \n",
      "\tLOC: 洛杉矶\n",
      "\tPER: 陈特安\n",
      "\tPER: 何洪泽\n",
      "\tORG: 洛杉矶市民议政论坛\n",
      "\tORG: 亚洲协会南加中心\n",
      "\tORG: 美中\n",
      "\tORG: 全国委员会\n",
      "\tORG: 美中友协美西分会\n",
      "\tLOC: 比佛利山\n",
      "\tORG: 希尔顿饭店\n",
      "\tLOC: 洛杉矶\n",
      "\tLOC: 中国\n",
      "\tPER: 江泽民\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def pred_sentence(data):\n",
    "    df = pd.DataFrame(data) \n",
    "    # 调用 extract_sentence_features 函数生成特征 \n",
    "    sentence_features = list(extract_sentence_features(df))\n",
    "    test = []\n",
    "    test.append(sentence_features)\n",
    "    pred = crf.predict(test)\n",
    "    return pred\n",
    "\n",
    "def pred_result(tags):\n",
    "    output = ''\n",
    "    idx = 0\n",
    "    for idx in range(len(tags)):\n",
    "        if tags[idx] != 'O':\n",
    "            output += Tokens[idx]\n",
    "            if (idx+1)<len(tags) and tags[idx+1]=='O':\n",
    "                print('\\t'+Tags[idx][2:] + ': ' + output)\n",
    "        else:\n",
    "            output = ''\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "data = test_df[test_df['Sentence_Index']==90]\n",
    "pred = pred_sentence(data)\n",
    "\n",
    "str = ''\n",
    "for t in list(data['Token']):\n",
    "    str += t\n",
    "print(str)\n",
    "Tokens = list(data['Token'])\n",
    "Tags = list(data['Tag'])\n",
    "preds = list(pred[0])\n",
    "\n",
    "print('test data: ')\n",
    "pred_result(Tags)\n",
    "print('\\npred result: ')\n",
    "pred_result(preds)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
